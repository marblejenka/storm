---
title: FAQ
layout: documentation
documentation: true
---

## Best Practices

### What rules of thumb can you give me for configuring Storm+Trident?

* ワーカーの数はマシン数の倍数とします; parallelismはワーカー数の倍数とし; Kafkaのパーティション数はSpoutの並列度の倍数とします
* 1つのワーカーに対して1つのトポロジ、1つのトポロジに対して1つのマシンを使用します
* より少ない、より大きなアグリゲータからから出発し、1台のマシンに1つのワーカーがを用意する
* Isolation schedulerを使用する
* 1つのワーカーに対して1つのackerを使用する -- 0.9からはデフォルトにしていますが、以前のバージョンではそうではありません。
* GCロギングを有効にする; うまくいっている状態では、大きなGCはほとんど発生しません。
* Tridentのbatch millisを典型的なエンドツーエンドレイテンシーの約50％に設定します。
* 保留できるSpoutの最大値を、小さいと確信できる値からはじめる-- Tridentの場合は1つ、またはStormのエグゼキュータの数だけ -- そこから、流量に変化が見えなくなるまで、Spoutを増やしてください。おそらく `2*(throughput in recs/sec)*(end-to-end latency)`（リトルの法則におけるキャパシティの2倍程度）近傍に落ち着くでしょう。

### What are some of the best ways to get a worker to mysteriously and bafflingly die?

* ログディレクトリへの書き込み権限を持っていますか？
* ヒープが使い尽くされてませんか？
* すべてのワーカーにに適切なライブラリがすべてインストールされていますか？
* Zookeeperのホスト名がlocalhostに設定されていませんか？
* それぞれのワーカーに正確でかつユニークなホスト名 -- マシンそのものの名前解決もできるように -- を指定して、それをStormの設定ファイルに記述しましたか？
* ファイアウォール/セキュリティグループのパーミッションを、a) すべてのワーカー、b) Stormのマスター、c) Zookeeperの間で_双方向_にオープンしましたか？ワーカーからあなたのトポロジーがアクセスするkafka/kestrel/database/etcについてはどうですか？ netcatを使用して適切なポートを突き止めてください。

### Halp! I cannot see:

* **my logs** ログはデフォルトで$STORM_HOME/logsに配置されます。そのディレクトリへの書き込み権限があることを確認してください。それらはog4j2/{cluster, worker}.xmlで設定されます。
* **final JVM settings** childoptsに`-XX+PrintFlagsFinal`コマンドラインオプションを追加します（設定ファイルを参照）
* **final Java system properties** トポロジを組み立てる実装に近いところに、`Properties props = System.getProperties(); props.list(System.out);`を追加します。

### How many Workers should I use?

ワーカーの総数はスーパーバイザーによって設定されます -- スーパーバイザーが監督するJVMスロットがいくつかあります。トポロジで設定できるものは、トポロジが要求しようとするワーカースロットの数です。

マシンごと、トポロジごとに複数のワーカーを使用する大きな理由はありません。

1つのトポロジが8コアのノード3台にparallelism hintが24で実行されている場合、各ボルトはマシンごとに8つのエグゼキュータ、つまり各コアごとに1つのエグゼキュータを取得します。3つのワーカー（それぞれ8つのエグゼキュータが割り当てられる）を実行することには、24のワーカー（それぞれのエグゼキュータに1つ割り当て）を動かすのと比較して、3つの大きなメリットがあります。

まず、同じワーカーのエグゼキュータに再分割されたデータ（シャッフルまたはgroup-by）は、転送バッファをヒットする必要がありません。代わりに、タプルは、送信バッファから受信バッファに直接格納されます。それは大きな勝利です。対照的に、送り先のエグゼキュータが同じマシンの別のワーカーにある場合は、send -> worker transfer -> local socket -> worker recv -> exec recv bufferという経路をたどります。それはネットワークカードをヒットしませんが、エグゼキュータが同じワーカーにいる場合と同じくらい大きな勝利はありません。

次に、バッキングキャッシュを小さくした24個のアグリゲータを持つよりも、非常に大きなバッキングキャッシュを持つ3個のアグリゲータを使用する方が良いでしょう。これにより、スキューの影響が軽減され、LRU効率が向上します。

最後に、ワーカーを少なくすることにより制御の流れにおける無駄が少なくなります。

## Topology

### Can a Trident topology have Multiple Streams?

> Tridentトポロジは、(if-else)のような条件付きパスを持つワークフローのように機能できますか?例えば、Spout(S1)がBolt(B0)に接続し、Bolt(B0)が入力タプルの特定の値に基づいて、Bolt(B1)またはBolt(B2)のいずれか一方に入力をルーティングするようなものです。

Tridentの"each"演算子は、変数に格納できるStreamオブジェクトを返します。同じストリームで複数のeach演算子の結果を分割して実行することができます（例：

        Stream s = topology.each(...).groupBy(...).aggregate(...) 
        Stream branch1 = s.each(..., FilterA) 
        Stream branch2 = s.each(..., FilterB) 

join、merge、またはmultiReduceを使用してストリームを結合できます。

執筆時点では、Tridentから複数の出力ストリームには送出できません -- [STORM-68](https://issues.apache.org/jira/browse/STORM-68)を参照してください。

### Why am I getting a NotSerializableException/IllegalStateException when my topology is being started up?

Stormのライフサイクル内では、トポロジがインスタンス化された後、トポロジが実行される前にZooKeeperに格納されるバイト形式に直列化されます。このステップでにおいて、トポロジ内のSpoutまたはBoltが直列化不可能なプロパティで初期化されている場合、直列化は失敗します。直列化不可能なフィールドが必要な場合は、トポロジがワーカーに渡された後に実行されるBoltまたはSpoutのprepareメソッド内で初期化します。

## Spouts

### What is a coordinator, and why are there several?

TridentのSpoutは実際にはStormの_Bolt_の中で実行されます。TridentのトポロジのStorm-SpoutはMasterBatchCoordinatorです -- Tridentのバッチを調節するもので、使用するSpoutに関係なく同じです。バッチは、MBCが各Spout-coordinatorにシードタプルを分配するときに生まれます。Spout-coordinatorのBoltは、あなたの特定のSpoutがどのように協力すべきかを知っています -- Kafkaの場合、各Spoutがどのパーティションやオフセットレンジからからpullするかを決めるのを助けます。

### What can I store into the spout's metadata record?

できるだけ小さく静的なデータをメタデータレコードに保存するようにしてください（メモ：おそらくもっと興味深いものを保存することはできますが、そうすべきではありません）

### How often is the 'emitPartitionBatchNew' function called?

MBCは実際のSpoutであるため、バッチ内のすべてのタプルはそのタプルツリーのメンバーにすぎません。つまり、Stormの設定"max spout pending"は、Tridentが並行に実行するバッチ数を効果的に定義します。 MBCは、保持するタプル数がmax-spendingより少なく、最後のバッチ以降に少なくとも1つの[trident batch interval]({{page.git-blob-base}}/conf/defaults.yaml#L115)秒が経過した場合、新しいバッチを送出します。

### If nothing was emitted does Trident slow down the calls?

はい、プラグイン可能な"spout wait strategy"があります。デフォルトでは[設定可能な時間]({{page.git-blob-base}}/conf/defaults.yaml#L110)の間スリープします。

### OK, then what is the trident batch interval for?

あなたは486がどのように[ターボボタン](http://en.wikipedia.org/wiki/Turbo_button)を持っていたのか知​​っていますか？それとにたようなものです。

実際には、2つの実用的な用途があります。 1つは、スロットル処理を行わずにリモートソースをポーリングするSpoutをスロットルできることです。たとえば、新しいバッチアップロードファイルを読み込み、改行して出力するために、指定されたS3バケットを監視するSpoutがあるとします。数秒ごとにS3をたたきに行くのは望ましくありません。ファイルは数分に1回以上更新されるわけでなく、バッチ処理に数秒かかります。

もう1つは、スタートアップ時や重いバースト負荷のときに内部キューの過圧を制限することです -- Spoutが活性化して10バッチ分のレコードをシステムにいきなり詰め込むとすると、バッチ7からの緊急度の低いタプルを転送バッファを詰まらせ、バッチ3からの$commitタプルを妨げることになります（またはバッチ3からの通常の古いタプルさえも）。我々が行うことは、トライデントのバッチ間隔を典型的なエンドツーエンドの処理レイテンシの約半分に設定することです -- バッチを処理するのに600msかかる場合は、300msごとにバッチを開始するだけです。

これはキャップであり、追加の遅延ではないことに注意してください -- つまり300msの周期で動作するので、バッチが258msかかった場合はTridentはさらに42msだけ遅延させることになります。

### How do you set the batch size?

Tridentはバッチ数に独自の制限を設けていません。Kafka Spoutの場合、最大フェッチバイトサイズを平均レコードサイズで割った値が、サブバッチパーティションごとの効率的なレコード数を定義します。

### How do I resize a batch?

トライデントバッチは、いささか多重定義された機能です。パーティションの数とともに、バッチサイズは制約されるか定義されます

1. トランザクション安全性の単位（タプルについてのリスクと時間のトレードオフ）
2. パーティションごとの、ウィンドウによるストリーム解析のための効率的ななウィンドウ機構
3. パーティションごとの、partitionQuery、partitionPersistなどによって実行される同時クエリの数。
4. パーティションごとの、Spoutが同時にディスパッチするのに便利なレコードの数。

いったん生成されると、バッチ全体のサイズを変更することはできませんが、パーティション数を変更することはできます -- シャッフルしてから、parallelism hintを変更します

## Time Series

### How do I aggregate events by time?

不変のタイムスタンプを持つレコードがあり、それを数えたり、平均をとったり、離散時間のバケットに集約したりする場合、Tridentはスケーラブルである優れたソリューションです。

タイムスタンプをタイムバケットに変換する`Each`関数を書きましょう: バケツのサイズが"時次"の場合、タイムスタンプ`2013-08-08 12:34:56`は、時間バケット`2013-08-08 12:00:00`に対応付けられ、そして12時台の他のものもそうなります。その後、そのタイムバケットをグループ化し、グループ化されたpersistentAggregateを使用します。persistentAggregateは、データストアによってバックアップされたローカルのcacheMapを使用します。多くのレコードを持つグループでも、効率的な一括読み込みと書き込みを使用するため、データストアからの読み取りはほとんど必要ありません。あなたのデータフィードが比較的迅速である限り、Tridentはメモリとネットワークを非常に効率的に使用します。サーバーが1日の間にオフラインとなって1日分のデータを急いで配信しても、古い結果はゆっくりと取得され、更新されます -- 現在の結果の計算には影響を与えません。

### How can I know that all records for a time bucket have been received?

すべてのイベントが収集されたことを知ることはできません -- これは認識論上の課題であり、分散システムの課題ではありません。できることはといえば:

* ドメイン知識を使って時間制限を設定する
* _punctuation_を導入する: 指定されたタイムバケット内のすべてのレコードの後に​​来るレコードがあるとします。Tridentは、この枠組みを使用してバッチがいつ完了したかを知ります。たとえば、一連のセンサーから、そのセンサーの順番でレコードを受信した場合、すべてのセンサーが3:02:xx以降のタイムスタンプを送信した後ならコミットできることがわかります。
* 可能であれば、あなたのプロセスを増分的にしてください: それぞれの価値は答えをより真実に近いものにします。TridentのReducerAggregatorは、直近の結果と一連の新しいレコードを取り、新しい結果を返す演算子です。これにより、結果がキャッシュされ、データストアにシリアライズされます。サーバーが1日間オフラインになってから復旧し、1日分のデータを急いで戻すと、古い結果がゆっくりと取得され、更新されます。
* Lambda architecture: アーカイブ・ストア(S3、HBase、HDFS)に受け取ったすべてのイベントを記録します。fast layerでは、タイムウィンドウがクリアされたら、バケットを処理して実行可能な回答を得て、タイムウィンドウより古いものはすべて無視します。グローバルアグリゲーションを定期的に実行して、"正確な"答えを計算します。
